{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer detection using features from biopsied cells\n",
    "\n",
    "## Out line of the problem\n",
    "- ### Develop means to help doctors diagnose breast cancer based on features of biopsied breast cells.\n",
    "\n",
    "- ### Each feature requires time and money to collect.\n",
    "\n",
    "- ### Find the most cost-effective method of detecting malignancy.\n",
    "\n",
    "## Approach\n",
    "- ### Develop a two-tier classification system that can achieve high accuracy without using too much resourses.\n",
    "\n",
    "- ### First step will focus on achieving high recall with few features. Subjects whose cells were classified as malignant will advance to step two.\n",
    "\n",
    "- ### Second step will focus on increasing accuracy with all features.\n",
    "\n",
    "## Summary\n",
    "- ### First use a logistic regression model that uses only one feature \"Bare Nuclei\" to calculate the probability of the cells being malignant. Categorize all subjects with probability higher than 30% as \"malignant\" to increase recall.\n",
    "\n",
    "- ### For subjects categorized as \"malignant\", use a logistic regression model that uses all the features to accurately cateogorize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "color = sb.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import preprocessing as pp \n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the original data file received. Remove the description and save as an excel file in the data directory. \n",
    "\n",
    "### while inspecting the data, noticed that:\n",
    "\n",
    "- There are missing values.\n",
    "- There are duplicate data.\n",
    "- There are features whose values are larger than 10.\n",
    "\n",
    "### Read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the provided data (after deleting the data description line and saving it as .xlsx) to pandas dataframe\n",
    "current_path = os.getcwd()\n",
    "file = '/datasets/BreastCancerDetection/breast-cancer-wisconsin.xlsx'\n",
    "original_data = pd.read_excel(current_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the data type to float. Any non-numeric values will become NaN\n",
    "original_data_numeric = pd.DataFrame().reindex_like(original_data)\n",
    "\n",
    "#Run a for loop to change each column to float type\n",
    "for index in range(original_data.shape[1]):\n",
    "   \n",
    "   # Select column by index position using iloc[]\n",
    "    original_data_numeric.iloc[:,index] = (pd.to_numeric(original_data.iloc[:,index], errors='coerce'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all rows that contain NaN for now.\n",
    "data_without_nan = original_data_numeric.dropna()\n",
    "#Use 'index' as row index.\n",
    "data_without_nan = data_without_nan.set_index('index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate rows (use the first one as unique)\n",
    "data_without_nan.drop_duplicates(inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove data that's out of range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some values are going above the 10. Chose rows that have values equal to or less than 10.\n",
    "\n",
    "data_without_nan_filtered = data_without_nan[(data_without_nan['Clump Thickness'] <= 10) & (data_without_nan['Uniformity of Cell Size'] <= 10)] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the features are skewed. Log transform them to bring it closer to normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_without_nan_filtered.iloc[:,1:10]\n",
    "transformed_features = features.apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the features (subtract mean and divide by the standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_feature = pp.StandardScaler().fit(transformed_features)\n",
    "transformed_features_normalized = scaler_feature.transform(transformed_features)\n",
    "transformed_features_normalizedDF = pd.DataFrame(data=transformed_features_normalized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build logistic regression model using all the features. Aim for high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "cancer_state = data_without_nan_filtered.iloc[:,10]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_features_normalizedDF, cancer_state, test_size = 0.2,stratify=cancer_state)\n",
    "\n",
    "clf = LogisticRegressionCV(cv=5).fit(X_train, y_train)\n",
    "predicted_label = clf.predict(X_test)\n",
    "    \n",
    "score = clf.score(X_test, y_test)\n",
    "#accuracy score\n",
    "print(score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[86  2]\n",
      " [ 1 46]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, predicted_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the coefficients in this model to identify a feature with the highest predictive value. Identify that a feature \"Bare Nuclei\" has the highest coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90388066, 0.674033  , 0.8716097 , 0.31240304, 0.27714243,\n",
       "        1.03896015, 0.72251143, 0.51586553, 0.49034507]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a logist regression model with just \"Bare Nuclei\" and see how accurate it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(transformed_features_normalizedDF.iloc[:,5:6], cancer_state, test_size = 0.2,stratify=cancer_state)\n",
    "\n",
    "clf2 = LogisticRegressionCV(cv=5).fit(X_train2, y_train2)\n",
    "predicted_label2 = clf2.predict(X_test2)\n",
    "    \n",
    "score2 = clf2.score(X_test2, y_test2)\n",
    "print(score2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of 92.5 % is close to the accuracy of the full model. Check the confusion matrix to see how many false negatives we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84  4]\n",
      " [ 6 41]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test2, predicted_label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the predicted probability of the each test data and see if any of the 4 false negatives were close to becoming positive (default categorization probability of 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f7b547fc1d0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_proba2 = clf2.predict_proba(X_test2)\n",
    "predicted_proba2_df = pd.DataFrame(data=predicted_proba2[y_test2 == 2.0,0])\n",
    "predicted_proba2_df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed inspection of the probability shows that decreasing the categorization threshold to 0.3 will reduce the false negative to zero in this particular test set, at the expense of increasing the falst postive by 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72739015, 0.90242259, 0.90242259, 0.90242259, 0.56323553,\n",
       "       0.90242259, 0.56323553, 0.90242259, 0.90242259, 0.34034528,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.72739015, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.34034528, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.34034528, 0.90242259, 0.90242259, 0.72739015, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.34034528, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.72739015, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.90242259, 0.90242259, 0.90242259, 0.90242259, 0.90242259,\n",
       "       0.56323553, 0.90242259, 0.90242259])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba2[y_test2 == 2.0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12956938, 0.12956938, 0.34034528, 0.18173898, 0.12956938,\n",
       "       0.72739015, 0.12956938, 0.12956938, 0.12956938, 0.12956938,\n",
       "       0.12956938, 0.12956938, 0.12956938, 0.34034528, 0.22008878,\n",
       "       0.34034528, 0.12956938, 0.56323553, 0.12956938, 0.12956938,\n",
       "       0.34034528, 0.34034528, 0.12956938, 0.56323553, 0.34034528,\n",
       "       0.34034528, 0.12956938, 0.34034528, 0.12956938, 0.12956938,\n",
       "       0.12956938, 0.90242259, 0.90242259, 0.15240915, 0.15240915,\n",
       "       0.90242259, 0.12956938, 0.22008878, 0.12956938, 0.12956938,\n",
       "       0.27116659, 0.12956938, 0.12956938, 0.12956938, 0.43497184,\n",
       "       0.18173898, 0.43497184])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba2[y_test2 == 4.0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For subjects above the probability of 0.3, run a second round of classification using the second model. Now there is only one false positive and one false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87  1]\n",
      " [ 1 15]]\n"
     ]
    }
   ],
   "source": [
    "#Select the subjects that would go into the second round if we set the threshold at 0.3 probability\n",
    "X_test3 = X_test2.loc[predicted_proba2[:,0]>0.3]\n",
    "y_test3 = y_test2.loc[predicted_proba2[:,0]>0.3]\n",
    "\n",
    "#Select the full features for those subjects.\n",
    "X_test3_full = transformed_features_normalizedDF[transformed_features_normalizedDF.index.isin(X_test3.index)]\n",
    "\n",
    "#sort the y_test3 values based on the index (because the X_test3_full will be sorted according to the index)\n",
    "y_test3.sort_index(inplace=True)\n",
    "#prediction for those subjects using the full model.\n",
    "predicted_label3 = clf.predict(X_test3_full)\n",
    "print(metrics.confusion_matrix(y_test3, predicted_label3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "- ### By using two tier logistic regression model, doctors can reduce the cost of testing by measuring only one feature for the majority of subjects, while still maintaining high accuracy of the test.\n",
    "\n",
    "- ### In the first step, the doctors will just use \"Bare Nuclei\" feature and use logistic regression with the threshold of 30% probability to identify potentially malignant cells.\n",
    "\n",
    "- ### In the second step, the doctors will use all features to maximize the accuracy.\n",
    "\n",
    "## Future directions\n",
    "\n",
    "- ### Try to reduce the number of features in the full feature model to see if we can maintain the accuracy with less feature"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
